{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/opt/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/opt/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/opt/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/opt/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/opt/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/opt/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import os\n",
    "from data import CIFAR10Dataset, Imagenet32Dataset\n",
    "from models.embedders import BERTEncoder, OneHotClassEmbedding, UnconditionalClassEmbedding, GPTEncoder\n",
    "import torch\n",
    "from models.cgan import CDCGAN_G, CDCGAN_D\n",
    "from torch.optim import lr_scheduler\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "from tensorboardX import SummaryWriter\n",
    "import numpy as np\n",
    "import torchvision.utils as vutils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "from utils.evalutils import sample_image, sample_final, load_model, sample_for_inception, real_imgs, sample_final_tier2\n",
    "from inception import inception_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting params\n",
    "batch_size = 32\n",
    "use_cuda = 1\n",
    "n_filters=128\n",
    "z_dim=100\n",
    "output_dir=\"outputs/cgan_cifar10\"\n",
    "model_checkpoint=\"outputs/cgan_cifar10/models/epoch_81.pt\"\n",
    "print_every=10\n",
    "dataset=\"cifar10\"\n",
    "conditioning=\"bert\"\n",
    "device = torch.device(\"cuda\") if (torch.cuda.is_available() and use_cuda) else torch.device(\"cpu\")\n",
    "# n_epochs =150\n",
    "# lr=0.0001\n",
    "# lr_decay=0.99\n",
    "# n_cpu=8\n",
    "# sample_interval=100\n",
    "# eval_dir = \"outputs/cgan_cifar10/eval\"\n",
    "# debug=0\n",
    "# train_on_val=0\n",
    "# train=1\n",
    "#choices=[\"unconditional\", \"one-hot\", \"bert\", \"gpt\"]\n",
    "# setup device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device is cuda\n"
     ]
    }
   ],
   "source": [
    "print(\"Device is {}\".format(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading data file 1/1, datasets/ImageNet32/val/val_data.npz\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# Imagenet and CIFAR dataloaders\n",
    "imagenet_dataset = Imagenet32Dataset(train=0, max_size=-1)\n",
    "cifar_dataset = CIFAR10Dataset(train=0, max_size=-1)\n",
    "imagenet_val_dataloader = torch.utils.data.DataLoader(\n",
    "    imagenet_dataset,\n",
    "    batch_size,\n",
    "    shuffle=True,\n",
    "    drop_last=True\n",
    ")\n",
    "cifar_val_dataloader = torch.utils.data.DataLoader(\n",
    "    cifar_dataset,\n",
    "    batch_size,\n",
    "    shuffle=True,\n",
    "    drop_last=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1562"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check len\n",
    "len(imagenet_val_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "312"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cifar_val_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize embedder\n",
    "unconditional_encoder = UnconditionalClassEmbedding()\n",
    "bert_encoder = BERTEncoder()\n",
    "gpt_encoder = GPTEncoder()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# init generator model\n",
    "# model_G = CDCGAN_G(z_dim=z_dim, embed_dim=768, n_filters=n_filters)\n",
    "model_G_cifar10_baseline = CDCGAN_G(z_dim=z_dim, embed_dim=768, n_filters=n_filters)\n",
    "model_G_imagenet_baseline = CDCGAN_G(z_dim=z_dim, embed_dim=768, n_filters=n_filters)\n",
    "model_G_cifar10_gpt = CDCGAN_G(z_dim=z_dim, embed_dim=768, n_filters=n_filters)\n",
    "model_G_cifar10_gptsigmoid = CDCGAN_G(z_dim=z_dim, embed_dim=768, n_filters=n_filters)\n",
    "model_G_cifar10_wgan = CDCGAN_G(z_dim=z_dim, embed_dim=768, n_filters=n_filters)\n",
    "# model_G.weight_init(mean=0.0, std=0.02)\n",
    "# model_G = model_G.to(device)\n",
    "# state_dict = torch.load(model_checkpoint, map_location=torch.device('cpu'))['G']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model checkpoints\n",
    "cgan_cifar10_baseline = \"outputs/cgan_cifar10/models\"\n",
    "cgan_imagenet_baseline = \"outputs/cgan_imagenet/models\"\n",
    "cgan_cifar10_gpt = \"outputs/cgan_gpt/models\"\n",
    "cgan_cifar10_gptsigmoid = \"outputs/cgan_gpt_sigmoid/models\"\n",
    "cgan_cifar10_wgan = \"outputs/wcgan_cifar10/models\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sample images from most trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample images: baseline CIFAR\n",
    "model_checkpoint = os.path.join(cgan_cifar10_baseline, \"epoch_\" + str(81) + \".pt\")\n",
    "load_model(model_checkpoint, model_G_cifar10_baseline, torch.device('cpu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/torch/nn/functional.py:1339: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved  outputs/cgan_cifar10/samples/final_sample\n"
     ]
    }
   ],
   "source": [
    "sample_final(model_G_cifar10_baseline, bert_encoder, \"outputs/cgan_cifar10\",\n",
    "             n_row=4, dataloader=cifar_val_dataloader, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved  outputs/cgan_cifar10/samples/final_sample_tier2_2\n"
     ]
    }
   ],
   "source": [
    "sample_final_tier2(model_G_cifar10_baseline, bert_encoder, \"outputs/cgan_cifar10\",\n",
    "             n_row=4, caption_file=\"map_clsloc2.txt\", device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved  outputs/cgan_cifar10/samples/final_sample_tier2_3\n"
     ]
    }
   ],
   "source": [
    "sample_final_tier2(model_G_cifar10_baseline, bert_encoder, \"outputs/cgan_cifar10\",\n",
    "             n_row=4, caption_file=\"map_clsloc3.txt\", device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample images: basline imagenet\n",
    "model_checkpoint = os.path.join(cgan_imagenet_baseline, \"epoch_\" + str(7) + \".pt\")\n",
    "load_model(model_checkpoint, model_G_imagenet_baseline, torch.device('cpu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved  outputs/cgan_imagenet/samples/final_sample\n"
     ]
    }
   ],
   "source": [
    "sample_final(model_G_imagenet_baseline, bert_encoder, \"outputs/cgan_imagenet\",\n",
    "             n_row=4, dataloader=imagenet_val_dataloader, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved  outputs/cgan_imagenet/samples/final_sample_tier2_2\n"
     ]
    }
   ],
   "source": [
    "sample_final_tier2(model_G_imagenet_baseline, bert_encoder, \"outputs/cgan_imagenet\",\n",
    "             n_row=4, caption_file=\"map_clsloc2.txt\", device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved  outputs/cgan_imagenet/samples/final_sample_tier2_3\n"
     ]
    }
   ],
   "source": [
    "sample_final_tier2(model_G_imagenet_baseline, bert_encoder, \"outputs/cgan_imagenet\",\n",
    "             n_row=4, caption_file=\"map_clsloc3.txt\", device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample images: CIFAR GPT\n",
    "model_checkpoint = os.path.join(cgan_cifar10_gpt, \"epoch_\" + str(99) + \".pt\")\n",
    "load_model(model_checkpoint, model_G_cifar10_gpt, torch.device('cpu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved  outputs/cgan_gpt/samples/final_sample\n"
     ]
    }
   ],
   "source": [
    "sample_final(model_G_cifar10_gpt, gpt_encoder, \"outputs/cgan_gpt\",\n",
    "             n_row=4, dataloader=cifar_val_dataloader, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved  outputs/cgan_gpt/samples/final_sample_tier2_2\n"
     ]
    }
   ],
   "source": [
    "sample_final_tier2(model_G_cifar10_gpt, gpt_encoder, \"outputs/cgan_gpt\",\n",
    "             n_row=4, caption_file=\"map_clsloc2.txt\", device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved  outputs/cgan_gpt/samples/final_sample_tier2_3\n"
     ]
    }
   ],
   "source": [
    "sample_final_tier2(model_G_cifar10_gpt, gpt_encoder, \"outputs/cgan_gpt\",\n",
    "             n_row=4, caption_file=\"map_clsloc3.txt\", device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample images: CIFAR GPT with sigmoid\n",
    "model_checkpoint = os.path.join(cgan_cifar10_gptsigmoid, \"epoch_\" + str(122) + \".pt\")\n",
    "load_model(model_checkpoint, model_G_cifar10_gptsigmoid, torch.device('cpu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved  outputs/cgan_gpt_sigmoid/samples/final_sample\n"
     ]
    }
   ],
   "source": [
    "sample_final(model_G_cifar10_gptsigmoid, gpt_encoder, \"outputs/cgan_gpt_sigmoid\",\n",
    "             n_row=4, dataloader=cifar_val_dataloader, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved  outputs/cgan_gpt_sigmoid/samples/final_sample_tier2_2\n"
     ]
    }
   ],
   "source": [
    "sample_final_tier2(model_G_cifar10_gptsigmoid, gpt_encoder, \"outputs/cgan_gpt_sigmoid\",\n",
    "             n_row=4, caption_file=\"map_clsloc2.txt\", device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved  outputs/cgan_gpt_sigmoid/samples/final_sample_tier2_3\n"
     ]
    }
   ],
   "source": [
    "sample_final_tier2(model_G_cifar10_gptsigmoid, gpt_encoder, \"outputs/cgan_gpt_sigmoid\",\n",
    "             n_row=4, caption_file=\"map_clsloc3.txt\", device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample images: WCGAN CIFAR\n",
    "model_checkpoint = os.path.join(cgan_cifar10_wgan, \"epoch_\" + str(92) + \".pt\")\n",
    "load_model(model_checkpoint, model_G_cifar10_wgan, torch.device('cpu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved  outputs/wcgan_cifar10/samples/final_sample\n"
     ]
    }
   ],
   "source": [
    "sample_final(model_G_cifar10_wgan, bert_encoder, \"outputs/wcgan_cifar10\",\n",
    "             n_row=4, dataloader=cifar_val_dataloader, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved  outputs/wcgan_cifar10/samples/final_sample_tier2_2\n"
     ]
    }
   ],
   "source": [
    "sample_final_tier2(model_G_cifar10_wgan, bert_encoder, \"outputs/wcgan_cifar10\",\n",
    "             n_row=4, caption_file=\"map_clsloc2.txt\", device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved  outputs/wcgan_cifar10/samples/final_sample_tier2_3\n"
     ]
    }
   ],
   "source": [
    "sample_final_tier2(model_G_cifar10_wgan, bert_encoder, \"outputs/wcgan_cifar10\",\n",
    "             n_row=4, caption_file=\"map_clsloc3.txt\", device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate inception score for true data\n",
    "(9.562877186875763, 0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "cifar_val_dataloader = torch.utils.data.DataLoader(\n",
    "    cifar_dataset,\n",
    "    100,\n",
    "    shuffle=True,\n",
    "    drop_last=True\n",
    ")\n",
    "imgs = [img for (img, labels_batch, captions_batch) in cifar_val_dataloader][0].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8.821857043548619, 0.0)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inception_score(imgs, resize = True)\n",
    "# (8.821857043548619, 0.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inception score for our models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3.1159828196134054, 0.0)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# GPT\n",
    "imgs_gpt = sample_for_inception(model_G_cifar10_gpt, gpt_encoder, \n",
    "                     100, dataloader=cifar_val_dataloader, device=device)\n",
    "inception_score(imgs_gpt, resize = True)\n",
    "# (3.1605518320034443, 0.0) 500 #this at 300\n",
    "# size of imgs is (320,3,32,32)\n",
    "# (3.069024780561485, 0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300, 3, 32, 32)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check\n",
    "imgs_gpt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3.0566969947586062, 0.0)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# baseline : NOTE this has batch size 300\n",
    "imgs_baseline = sample_for_inception(model_G_cifar10_baseline, bert_encoder, \n",
    "                     100, dataloader=cifar_val_dataloader, device=device)\n",
    "inception_score(imgs_baseline, resize = True)\n",
    "# (1.064679586315566, 0.0)\n",
    "# (3.0453448825573903, 0.0)\n",
    "# (3.110995859711864, 0.0) 500\n",
    "# (3.1048524864446625, 0.0) 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2.081028986475838, 0.0)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# wcgan\n",
    "imgs_wcgan = sample_for_inception(model_G_cifar10_wgan, bert_encoder, \n",
    "                     100, dataloader=cifar_val_dataloader, device=device)\n",
    "inception_score(imgs_wcgan, resize = True)\n",
    "#(2.102412739434052, 0.0)\n",
    "# (2.081028986475838, 0.0) 300"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save real images for FID score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_real = real_imgs(200, cifar_val_dataloader, device) # 100 imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_real_tensor = torch.from_numpy(imgs_real)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([300, 3, 32, 32])"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imgs_real_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(300):\n",
    "    vutils.save_image(imgs_real_tensor[i,:,:,:], 'outputs/real/{}.png'.format(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create fake images for FID Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# baseline\n",
    "imgs_baseline_tensor = torch.from_numpy(imgs_baseline)\n",
    "for i in range(300):\n",
    "    vutils.save_image(imgs_baseline_tensor[i,:,:,:], 'outputs/cgan_cifar10/fid/{}.png'.format(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gpt\n",
    "imgs_gpt_tensor = torch.from_numpy(imgs_gpt)\n",
    "for i in range(300):\n",
    "    vutils.save_image(imgs_gpt_tensor[i,:,:,:], 'outputs/cgan_gpt/fid/{}.png'.format(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wcgan\n",
    "imgs_wcgan_tensor = torch.from_numpy(imgs_wcgan)\n",
    "for i in range(300):\n",
    "    vutils.save_image(imgs_wcgan_tensor[i,:,:,:], 'outputs/wcgan_cifar10/fid/{}.png'.format(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# results\n",
    "\n",
    "131.25505595644205 for baseline\n",
    "\n",
    "135.2906583566559 for gpt\n",
    "\n",
    "164.5993704587727 for wcgan"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
